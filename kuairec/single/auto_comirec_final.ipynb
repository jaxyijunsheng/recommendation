{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd98390-6cf1-4188-8828-d9bbbeea1bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 10:16:09.927943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3b8cca-95eb-4e76-af74-8467884552ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a9ec17-4926-453d-8ca9-9113908b350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/root/autodl-tmp/workspace/datasets/kuairec/small_matrix.pkl', 'rb') as f:    \n",
    "    user_dict = pickle.load(f)\n",
    "items_num=max(max(user_dict.values()))\n",
    "maxlen=1000\n",
    "len_seq=100\n",
    "batch_size=1024\n",
    "epoch_num=20\n",
    "hidden_size=64\n",
    "keep_rate=0.9\n",
    "layers_num=2\n",
    "num_interest=1\n",
    "neg_num=4\n",
    "test_neg_num=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fd2c73-3e4f-449e-aef3-88288de30804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def sample(user_dict,maxlen,len_seq):\n",
    "    train_set=[]\n",
    "    train_val_set=[]\n",
    "    val_set=[]\n",
    "    test_set=[]\n",
    "    for u in user_dict.keys():\n",
    "        idx=0\n",
    "        hist=user_dict[u]        \n",
    "        hist=hist[-maxlen:-2]\n",
    "        #print(hist)\n",
    "        for i in range(1,len(hist)):\n",
    "            seq = np.zeros([len_seq], dtype=np.int32)\n",
    "            #print(hist[0:i])\n",
    "            seq[max(0,len_seq+idx-1):]=hist[max(0,i-len_seq):i]\n",
    "            idx+=-1\n",
    "            nxt = hist[i]\n",
    "            #print((u,seq,nxt))\n",
    "            train_set.append((u,list(seq),nxt))\n",
    "            #print(seq)\n",
    "        train_val_set.append((u,list(seq),nxt))\n",
    "        seq = np.zeros([len_seq], dtype=np.int32)\n",
    "        seq=hist[-len_seq-2:-2]\n",
    "        nxt = user_dict[u][-2]\n",
    "        val_set.append((u,list(seq),nxt))\n",
    "        seq = np.zeros([len_seq], dtype=np.int32)\n",
    "        seq=hist[-len_seq-1:-1]\n",
    "        nxt = user_dict[u][-1]\n",
    "        test_set.append((u,list(seq),nxt))\n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    return train_set,test_set,val_set,train_val_set\n",
    "            \n",
    "def non_zero_sample(user_dict,maxlen,len_seq):\n",
    "    train_set=[]\n",
    "    test_set=[]\n",
    "    val_set=[]\n",
    "    train_val_set=[]\n",
    "    for u in user_dict.keys():\n",
    "        idx=0\n",
    "        hist=user_dict[u]        \n",
    "        seq = np.zeros([len_seq], dtype=np.int32)\n",
    "        #print(np.shape(seq[-maxlen:]))\n",
    "        while(len(hist)<maxlen):\n",
    "            hist.insert(0,0)\n",
    "        #print(len(hist),hist)\n",
    "        hist=hist[-maxlen:-2]\n",
    "        for i in range(len_seq,len(hist)):\n",
    "            seq = np.zeros([len_seq], dtype=np.int32)\n",
    "            #rint(hist[max(0,i-len_seq):i])\n",
    "            seq=hist[max(0,i-len_seq):i]\n",
    "            idx+=-1\n",
    "            nxt = hist[i]\n",
    "            #print((u,seq,nxt))\n",
    "            neg_item = [random.randint(1, items_num) for _ in range(neg_num)]\n",
    "            train_set.append((u,list(seq),nxt,neg_item))\n",
    "            #print(seq)\n",
    "        #print(np.shape(hist[0:len(hist)-1]))\n",
    "        train_val_set.append((u,list(seq),nxt))\n",
    "        seq = np.zeros([len_seq], dtype=np.int32)\n",
    "        seq=hist[-len_seq-2:-2]\n",
    "        nxt = user_dict[u][-2]\n",
    "        neg_item = [random.randint(1, items_num) for _ in range(neg_num)]\n",
    "        val_set.append((u,list(seq),nxt,neg_item))\n",
    "        seq = np.zeros([len_seq], dtype=np.int32)\n",
    "        seq=hist[-len_seq-1:-1]\n",
    "        nxt = user_dict[u][-1]\n",
    "        neg_item = [random.randint(1, items_num) for _ in range(test_neg_num)]\n",
    "        test_set.append((u,list(seq),nxt,neg_item))\n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    return train_set,test_set ,val_set,train_val_set   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904dd44f-cae8-4e03-a8f7-a76fbffae7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267078 1411 1411 1411\n"
     ]
    }
   ],
   "source": [
    "train_set,test_set,val_set,train_val_set=non_zero_sample(user_dict,maxlen,len_seq)\n",
    "print(len(train_set),len(test_set),len(val_set),len(train_val_set))\n",
    "users_num=len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881ce4c1-a8b0-4c59-98db-5c6df6ae46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "users, click_seqs, pos_items,neg_items = zip(*train_set)\n",
    "train_data = {'click_seq': np.array(click_seqs), 'pos_item': np.array(pos_items),'neg_item':np.array(neg_items)}\n",
    "users, click_seqs, pos_items,neg_items = zip(*test_set)\n",
    "test_data = {'click_seq': np.array(click_seqs), 'pos_item': np.array(pos_items),'neg_item':np.array(neg_items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32879739-778f-4a8b-aabe-f2b701d2253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267078, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_data['neg_item']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df82d54-78b8-48b8-84b9-ad4896e2236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Attention Mechanism Function.\n",
    "    Args:\n",
    "        :param q: A 3d/4d tensor with shape of (None, ..., seq_len, dim)\n",
    "        :param k: A 3d/4d tensor with shape of (None, ..., seq_len, dim)\n",
    "        :param v: A 3d/4d tensor with shape of (None, ..., seq_len, dim)\n",
    "        :param mask: A 3d/4d tensor with shape of (None, ..., seq_len, 1)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mat_qk = tf.matmul(q, k, transpose_b=True)  # (None, seq_len, seq_len)\n",
    "    # Scaled\n",
    "    dk = tf.cast(k.shape[-1], dtype=tf.float32)\n",
    "    scaled_att_logits = mat_qk / tf.sqrt(dk)\n",
    "\n",
    "    paddings = tf.ones_like(scaled_att_logits) * (-2 ** 32 + 1)  # (None, seq_len, seq_len)\n",
    "    if mask!=None:\n",
    "        outputs = tf.where(tf.equal(mask, tf.zeros_like(mask)), paddings, scaled_att_logits)  # (None, seq_len, seq_len)\n",
    "    else:\n",
    "        outputs=scaled_att_logits\n",
    "    # softmax\n",
    "    outputs = tf.nn.softmax(logits=outputs)  # (None, seq_len, seq_len)\n",
    "    outputs = tf.matmul(outputs, v)  # (None, seq_len, dim)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def split_heads(x, seq_len, num_heads, depth):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    Args:\n",
    "        :param x: A Tensor with shape of [batch_size, seq_len, num_heads * depth]\n",
    "        :param seq_len: A scalar(int).\n",
    "        :param num_heads: A scalar(int).\n",
    "        :param depth: A scalar(int).\n",
    "    :return: A tensor with shape of [batch_size, num_heads, seq_len, depth]\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (-1, seq_len, num_heads, depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1382056-672c-4683-a46a-dca40cd582b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"Multi Head Attention Mechanism.\n",
    "        Args:\n",
    "            :param d_model: A scalar. The self-attention hidden size.\n",
    "            :param num_heads: A scalar. Number of heads. If num_heads == 1, the layer is a single self-attention layer.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model, activation=None)\n",
    "        self.wk = tf.keras.layers.Dense(d_model, activation=None)\n",
    "        self.wv = tf.keras.layers.Dense(d_model, activation=None)\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        q = self.wq(q)  # (None, seq_len, d_model)\n",
    "        k = self.wk(k)  # (None, seq_len, d_model)\n",
    "        v = self.wv(v)  # (None, seq_len, d_model)\n",
    "        # split d_model into num_heads * depth\n",
    "        seq_len, d_model = q.shape[1], q.shape[2]\n",
    "        q = split_heads(q, seq_len, self.num_heads, q.shape[2] // self.num_heads)  # (None, num_heads, seq_len, depth)\n",
    "        k = split_heads(k, seq_len, self.num_heads, k.shape[2] // self.num_heads)  # (None, num_heads, seq_len, depth)\n",
    "        v = split_heads(v, seq_len, self.num_heads, v.shape[2] // self.num_heads)  # (None, num_heads, seq_len, depth)\n",
    "        # mask\n",
    "        if mask!=None:\n",
    "            mask = tf.tile(tf.expand_dims(mask, axis=1), [1, self.num_heads, 1, 1])  # (None, num_heads, seq_len, 1)\n",
    "        # attention\n",
    "        scaled_attention = scaled_dot_product_attention(q, k, v, mask)  # (None, num_heads, seq_len, d_model // num_heads)\n",
    "        # reshape\n",
    "        outputs = tf.reshape(tf.transpose(scaled_attention, [0, 2, 1, 3]), [-1, seq_len, d_model])  # (None, seq_len, d_model)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class FFN(tf.keras.layers.Layer):\n",
    "    def __init__(self, hidden_unit, d_model):\n",
    "        \"\"\"Feed Forward Network.\n",
    "        Args:\n",
    "            :param hidden_unit: A scalar.\n",
    "            :param d_model: A scalar.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(FFN, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=hidden_unit, kernel_size=1, activation='relu', use_bias=True)\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=d_model, kernel_size=1, activation=None, use_bias=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        output = self.conv2(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads=1, ffn_hidden_unit=128, dropout=0., layer_norm_eps=1e-6):\n",
    "        \"\"\"Encoder Layer.\n",
    "        Args:\n",
    "            :param d_model: A scalar. The self-attention hidden size.\n",
    "            :param num_heads: A scalar. Number of heads.\n",
    "            :param ffn_hidden_unit: A scalar. Number of hidden unit in FFN\n",
    "            :param dropout: A scalar. Number of dropout.\n",
    "            :param layer_norm_eps: A scalar. Small float added to variance to avoid dividing by zero.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FFN(ffn_hidden_unit, d_model)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layer_norm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layer_norm_eps)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, mask= inputs\n",
    "        # self-attention\n",
    "        att_out = self.mha(x, x, x, mask)  # (None, seq_len, d_model)\n",
    "        att_out = self.dropout1(att_out)\n",
    "        # residual add\n",
    "        out1 = self.layernorm1(x + att_out)  # (None, seq_len, d_model)\n",
    "        # ffn\n",
    "        ffn_out = self.ffn(out1)\n",
    "        ffn_out = self.dropout2(ffn_out)\n",
    "        # residual add\n",
    "        out2 = self.layernorm2(out1 + ffn_out)  # (None, seq_len, d_model)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49fb9d25-6709-4545-9211-898760d749eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class comirec(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(comirec, self).__init__()\n",
    "        blocks=1\n",
    "        embed_reg=0.\n",
    "        layer_norm_eps=1e-6\n",
    "        num_heads=3\n",
    "        use_l2norm=False\n",
    "        \n",
    "        self.len_seq=len_seq\n",
    "        self.item_embedding = tf.keras.layers.Embedding(items_num+1,hidden_size,input_length=self.len_seq,\n",
    "                                                       embeddings_initializer='random_normal',\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.l2(embed_reg))\n",
    "        self.pos_embedding = tf.keras.layers.Embedding(len_seq,hidden_size,input_length=1,\n",
    "                                                       embeddings_initializer='random_normal',\n",
    "                                        embeddings_regularizer=tf.keras.regularizers.l2(embed_reg))\n",
    "        self.dropout = tf.keras.layers.Dropout(1-keep_rate)\n",
    "        self.w1_layer= tf.keras.layers.Dense(hidden_size * 4, activation='tanh')\n",
    "        self.w2_layer  = tf.keras.layers.Dense(num_heads, activation=None)\n",
    "        # norm\n",
    "        self.use_l2norm = use_l2norm\n",
    "        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        seq_embed=self.item_embedding(inputs['click_seq'])\n",
    "        pos_encoding = tf.expand_dims(self.pos_embedding(tf.range(self.len_seq)), axis=0)  # (1, seq_len, embed_dim)\n",
    "        seq_embed += pos_encoding\n",
    "\n",
    "        seq_embed = self.dropout(seq_embed)\n",
    "        att=self.w1_layer(seq_embed)#[b,len_seq,h]\n",
    "        att=self.w2_layer(att)#[b,len_seq,num_heads]\n",
    "        att=tf.transpose(att, [0, 2, 1])#[b,num_heads,len_seq]\n",
    "\n",
    "        att=tf.nn.softmax(att)\n",
    "        user_info=tf.matmul(att,seq_embed)#[b,num_interest,h]\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        pos_emb=self.item_embedding(tf.reshape(inputs['pos_item'], [-1, ]))\n",
    "        neg_emb=self.item_embedding(inputs['neg_item'])\n",
    "        \n",
    "        if self.use_l2norm:\n",
    "            pos_emb = tf.math.l2_normalize(pos_emb, axis=-1)\n",
    "            neg_emb = tf.math.l2_normalize(neg_emb, axis=-1)\n",
    "            user_info = tf.math.l2_normalize(user_info, axis=-1)\n",
    "        \n",
    "        \n",
    "        pos_score =tf.reduce_max(tf.reduce_sum(tf.multiply(user_info, tf.expand_dims(pos_emb, axis=1)), axis=-1),axis=-1,keepdims=True)  # (None, 1)\n",
    "        \n",
    "        neg_score = tf.reduce_max(tf.reduce_sum(tf.multiply(tf.expand_dims(user_info,axis=1), tf.expand_dims(neg_emb,axis=2)), axis=-1), axis=-1)\n",
    "        \n",
    "        pos_score = tf.tile(pos_score, [1, neg_score.shape[1]])\n",
    "        \n",
    "        loss = tf.reduce_mean(- tf.math.log(tf.nn.sigmoid(pos_score)) - tf.math.log(1 - tf.nn.sigmoid(neg_score))) / 2\n",
    "        self.add_loss(loss)\n",
    "        logits = tf.concat([pos_score, neg_score], axis=-1)\n",
    "        return logits\n",
    "    \n",
    "    def summary(self):\n",
    "        inputs = {\n",
    "            'click_seq': tf.keras.layers.Input(shape=(self.len_seq,), dtype=tf.int32),\n",
    "            'pos_item': tf.keras.layers.Input(shape=(), dtype=tf.int32),\n",
    "            'neg_item': tf.keras.layers.Input(shape=(1,), dtype=tf.int32)  # suppose neg_num=1\n",
    "        }\n",
    "        tf.keras.models.Model(inputs=inputs, outputs=self.call(inputs)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef04f38c-df08-4399-bbd0-f47bc1ee3213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             212992      input_1[0][0]                    \n",
      "                                                                 tf.reshape[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 100, 64)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100, 64)      0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100, 256)     16640       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100, 3)       771         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 3, 100)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None,)              0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 3, 100)       0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul (TFOpLambda)   (None, 3, 64)        0           tf.nn.softmax[0][0]              \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 1, 64)        0           embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 3, 64)        0           tf.linalg.matmul[0][0]           \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (None, 1, 3, 64)     0           tf.linalg.matmul[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_2 (TFOpLambda)   (None, 1, 1, 64)     0           embedding[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 3)            0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1, 3, 64)     0           tf.expand_dims_1[0][0]           \n",
      "                                                                 tf.expand_dims_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max (TFOpLambda) (None, 1)            0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 1, 3)         0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile (TFOpLambda)            (None, 1)            0           tf.math.reduce_max[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max_1 (TFOpLambd (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 2)            0           tf.tile[0][0]                    \n",
      "                                                                 tf.math.reduce_max_1[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 230,403\n",
      "Trainable params: 230,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = comirec()\n",
    "model.summary()\n",
    "optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab39a04b-df32-46da-93f0-7f2749da22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def eval_rank(pred_y, metric_names, k=10):\n",
    "    \"\"\"Evaluate\n",
    "        Args:\n",
    "            :param pred_y: A ndarray.\n",
    "            :param metric_names: A list like ['hr'].\n",
    "            :param k: A scalar(int).\n",
    "        :return: A result dict such as {'hr':, 'ndcg':, ...}\n",
    "    \"\"\"\n",
    "    rank = pred_y.argsort().argsort()[:, 0]\n",
    "    res_dict = {}\n",
    "    for name in metric_names:\n",
    "        if name == 'hr':\n",
    "            res = hr(rank, k)\n",
    "        elif name == 'ndcg':\n",
    "            res = ndcg(rank, k)\n",
    "        elif name == 'mrr':\n",
    "            res = mrr(rank, k)\n",
    "        else:\n",
    "            break\n",
    "        res_dict[name] = res\n",
    "    return res_dict\n",
    "\n",
    "def eval_pos_neg(model, test_data, metric_names, k=10, batch_size=None):\n",
    "    \"\"\"Evaluate the performance of Top-k recommendation algorithm.\n",
    "    Note: Test data must contain some negative samples(>= k) and one positive samples.\n",
    "    Args:\n",
    "        :param model: A model built-by tensorflow.\n",
    "        :param test_data: A dict.\n",
    "        :param metric_names: A list like ['hr'].\n",
    "        :param k: A scalar(int).\n",
    "        :param batch_size: A scalar(int).\n",
    "    :return: A result dict such as {'hr':, 'ndcg':, ...}\n",
    "    \"\"\"\n",
    "    pred_y = - model.predict(test_data, batch_size)\n",
    "    return eval_rank(pred_y, metric_names, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0933a7-b926-4371-a008-0e992c04d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 10:16:59.495380: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-10-20 10:16:59.502085: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000000000 Hz\n",
      "2022-10-20 10:17:01.075581: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15/1238 [..............................] - ETA: 14s - loss: 0.6925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 10:17:01.949384: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-10-20 10:17:01.949452: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238/1238 [==============================] - 19s 14ms/step - loss: 0.4540\n",
      "Iteration 1 Fit [20.7 s], Evaluate [0.3 s]: HR = 0.1510, MRR = 0.0559, NDCG = 0.0782\n",
      "1238/1238 [==============================] - 19s 15ms/step - loss: 0.3801\n",
      "Iteration 2 Fit [20.6 s], Evaluate [0.1 s]: HR = 0.1602, MRR = 0.0615, NDCG = 0.0848\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.3577\n",
      "Iteration 3 Fit [21.2 s], Evaluate [0.1 s]: HR = 0.1687, MRR = 0.0673, NDCG = 0.0913\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3456\n",
      "Iteration 4 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.1836, MRR = 0.0726, NDCG = 0.0990\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3381\n",
      "Iteration 5 Fit [22.2 s], Evaluate [0.1 s]: HR = 0.1956, MRR = 0.0783, NDCG = 0.1061\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3328\n",
      "Iteration 6 Fit [22.8 s], Evaluate [0.1 s]: HR = 0.2055, MRR = 0.0777, NDCG = 0.1081\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3287\n",
      "Iteration 7 Fit [22.7 s], Evaluate [0.5 s]: HR = 0.2069, MRR = 0.0790, NDCG = 0.1094\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3255\n",
      "Iteration 8 Fit [22.8 s], Evaluate [0.1 s]: HR = 0.2084, MRR = 0.0781, NDCG = 0.1090\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3229\n",
      "Iteration 9 Fit [22.6 s], Evaluate [0.1 s]: HR = 0.2041, MRR = 0.0751, NDCG = 0.1057\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3208\n",
      "Iteration 10 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2140, MRR = 0.0808, NDCG = 0.1124\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3190\n",
      "Iteration 11 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2041, MRR = 0.0744, NDCG = 0.1052\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3175\n",
      "Iteration 12 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2218, MRR = 0.0794, NDCG = 0.1131\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3161\n",
      "Iteration 13 Fit [23.0 s], Evaluate [0.1 s]: HR = 0.2133, MRR = 0.0771, NDCG = 0.1092\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.3148\n",
      "Iteration 14 Fit [21.3 s], Evaluate [0.5 s]: HR = 0.2162, MRR = 0.0769, NDCG = 0.1098\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3136\n",
      "Iteration 15 Fit [22.1 s], Evaluate [0.1 s]: HR = 0.2119, MRR = 0.0792, NDCG = 0.1106\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.3125\n",
      "Iteration 16 Fit [20.9 s], Evaluate [0.1 s]: HR = 0.2218, MRR = 0.0804, NDCG = 0.1138\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3113\n",
      "Iteration 17 Fit [21.9 s], Evaluate [0.1 s]: HR = 0.2240, MRR = 0.0863, NDCG = 0.1189\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3103\n",
      "Iteration 18 Fit [23.1 s], Evaluate [0.1 s]: HR = 0.2353, MRR = 0.0936, NDCG = 0.1272\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3092\n",
      "Iteration 19 Fit [22.8 s], Evaluate [0.1 s]: HR = 0.2339, MRR = 0.0847, NDCG = 0.1199\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3083\n",
      "Iteration 20 Fit [22.5 s], Evaluate [0.1 s]: HR = 0.2403, MRR = 0.0891, NDCG = 0.1248\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3073\n",
      "Iteration 21 Fit [42.5 s], Evaluate [0.5 s]: HR = 0.2424, MRR = 0.0934, NDCG = 0.1286\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3063\n",
      "Iteration 22 Fit [22.4 s], Evaluate [0.1 s]: HR = 0.2473, MRR = 0.0963, NDCG = 0.1320\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3055\n",
      "Iteration 23 Fit [23.0 s], Evaluate [0.1 s]: HR = 0.2388, MRR = 0.0900, NDCG = 0.1253\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3046\n",
      "Iteration 24 Fit [22.2 s], Evaluate [0.1 s]: HR = 0.2459, MRR = 0.0928, NDCG = 0.1289\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.3037\n",
      "Iteration 25 Fit [23.5 s], Evaluate [0.1 s]: HR = 0.2601, MRR = 0.1004, NDCG = 0.1383\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.3028\n",
      "Iteration 26 Fit [21.6 s], Evaluate [0.1 s]: HR = 0.2594, MRR = 0.0998, NDCG = 0.1375\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.3020\n",
      "Iteration 27 Fit [21.6 s], Evaluate [0.1 s]: HR = 0.2452, MRR = 0.0963, NDCG = 0.1316\n",
      "1238/1238 [==============================] - 17s 14ms/step - loss: 0.3012\n",
      "Iteration 28 Fit [17.9 s], Evaluate [0.4 s]: HR = 0.2466, MRR = 0.0908, NDCG = 0.1277\n",
      "1238/1238 [==============================] - 18s 14ms/step - loss: 0.3004\n",
      "Iteration 29 Fit [18.9 s], Evaluate [0.1 s]: HR = 0.2686, MRR = 0.0991, NDCG = 0.1392\n",
      "1238/1238 [==============================] - 19s 15ms/step - loss: 0.2997\n",
      "Iteration 30 Fit [20.1 s], Evaluate [0.1 s]: HR = 0.2651, MRR = 0.0997, NDCG = 0.1386\n",
      "1238/1238 [==============================] - 17s 14ms/step - loss: 0.2990\n",
      "Iteration 31 Fit [18.3 s], Evaluate [0.1 s]: HR = 0.2580, MRR = 0.0968, NDCG = 0.1350\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2983\n",
      "Iteration 32 Fit [21.4 s], Evaluate [0.1 s]: HR = 0.2679, MRR = 0.1016, NDCG = 0.1410\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2976\n",
      "Iteration 33 Fit [22.0 s], Evaluate [0.1 s]: HR = 0.2615, MRR = 0.0975, NDCG = 0.1363\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2970\n",
      "Iteration 34 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2658, MRR = 0.1024, NDCG = 0.1413\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2963\n",
      "Iteration 35 Fit [22.1 s], Evaluate [0.4 s]: HR = 0.2679, MRR = 0.1030, NDCG = 0.1422\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2957\n",
      "Iteration 36 Fit [21.6 s], Evaluate [0.1 s]: HR = 0.2629, MRR = 0.0999, NDCG = 0.1385\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2952\n",
      "Iteration 37 Fit [21.3 s], Evaluate [0.1 s]: HR = 0.2750, MRR = 0.1028, NDCG = 0.1435\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2947\n",
      "Iteration 38 Fit [21.2 s], Evaluate [0.1 s]: HR = 0.2750, MRR = 0.1055, NDCG = 0.1455\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2941\n",
      "Iteration 39 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2644, MRR = 0.1016, NDCG = 0.1402\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2935\n",
      "Iteration 40 Fit [21.0 s], Evaluate [0.1 s]: HR = 0.2771, MRR = 0.1071, NDCG = 0.1473\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2929\n",
      "Iteration 41 Fit [20.7 s], Evaluate [0.1 s]: HR = 0.2849, MRR = 0.1099, NDCG = 0.1514\n",
      "1238/1238 [==============================] - 17s 14ms/step - loss: 0.2925\n",
      "Iteration 42 Fit [18.4 s], Evaluate [0.4 s]: HR = 0.2792, MRR = 0.1100, NDCG = 0.1501\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2919\n",
      "Iteration 43 Fit [22.1 s], Evaluate [0.1 s]: HR = 0.2799, MRR = 0.1082, NDCG = 0.1487\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2915\n",
      "Iteration 44 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2807, MRR = 0.1136, NDCG = 0.1530\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2910\n",
      "Iteration 45 Fit [22.4 s], Evaluate [0.1 s]: HR = 0.2693, MRR = 0.1072, NDCG = 0.1456\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2907\n",
      "Iteration 46 Fit [22.5 s], Evaluate [0.1 s]: HR = 0.2764, MRR = 0.1104, NDCG = 0.1498\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2902\n",
      "Iteration 47 Fit [22.2 s], Evaluate [0.1 s]: HR = 0.2849, MRR = 0.1095, NDCG = 0.1511\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2898\n",
      "Iteration 48 Fit [22.3 s], Evaluate [0.1 s]: HR = 0.2934, MRR = 0.1158, NDCG = 0.1580\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2893\n",
      "Iteration 49 Fit [22.3 s], Evaluate [0.5 s]: HR = 0.2785, MRR = 0.1154, NDCG = 0.1541\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2889\n",
      "Iteration 50 Fit [22.2 s], Evaluate [0.1 s]: HR = 0.2849, MRR = 0.1173, NDCG = 0.1571\n",
      "1238/1238 [==============================] - 22s 17ms/step - loss: 0.2885\n",
      "Iteration 51 Fit [22.7 s], Evaluate [0.1 s]: HR = 0.2906, MRR = 0.1137, NDCG = 0.1556\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2883\n",
      "Iteration 52 Fit [22.5 s], Evaluate [0.1 s]: HR = 0.2899, MRR = 0.1166, NDCG = 0.1576\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2878\n",
      "Iteration 53 Fit [22.5 s], Evaluate [0.1 s]: HR = 0.2913, MRR = 0.1162, NDCG = 0.1578\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2874\n",
      "Iteration 54 Fit [22.0 s], Evaluate [0.1 s]: HR = 0.2906, MRR = 0.1140, NDCG = 0.1557\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2871\n",
      "Iteration 55 Fit [21.8 s], Evaluate [0.1 s]: HR = 0.2707, MRR = 0.1113, NDCG = 0.1491\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2868\n",
      "Iteration 56 Fit [21.5 s], Evaluate [0.5 s]: HR = 0.2884, MRR = 0.1164, NDCG = 0.1571\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2865\n",
      "Iteration 57 Fit [21.0 s], Evaluate [0.1 s]: HR = 0.2884, MRR = 0.1152, NDCG = 0.1563\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2861\n",
      "Iteration 58 Fit [20.8 s], Evaluate [0.1 s]: HR = 0.2814, MRR = 0.1139, NDCG = 0.1536\n",
      "1238/1238 [==============================] - 18s 15ms/step - loss: 0.2858\n",
      "Iteration 59 Fit [19.0 s], Evaluate [0.1 s]: HR = 0.2870, MRR = 0.1167, NDCG = 0.1570\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2854\n",
      "Iteration 60 Fit [23.1 s], Evaluate [0.1 s]: HR = 0.3005, MRR = 0.1243, NDCG = 0.1662\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2852\n",
      "Iteration 61 Fit [22.5 s], Evaluate [0.1 s]: HR = 0.2955, MRR = 0.1243, NDCG = 0.1648\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2849\n",
      "Iteration 62 Fit [22.3 s], Evaluate [0.1 s]: HR = 0.2920, MRR = 0.1219, NDCG = 0.1623\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2845\n",
      "Iteration 63 Fit [22.4 s], Evaluate [0.5 s]: HR = 0.2941, MRR = 0.1232, NDCG = 0.1636\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2842\n",
      "Iteration 64 Fit [22.4 s], Evaluate [0.1 s]: HR = 0.2906, MRR = 0.1219, NDCG = 0.1619\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2840\n",
      "Iteration 65 Fit [22.3 s], Evaluate [0.1 s]: HR = 0.2927, MRR = 0.1230, NDCG = 0.1632\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2837\n",
      "Iteration 66 Fit [22.2 s], Evaluate [0.1 s]: HR = 0.2884, MRR = 0.1196, NDCG = 0.1597\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2836\n",
      "Iteration 67 Fit [22.0 s], Evaluate [0.1 s]: HR = 0.2884, MRR = 0.1165, NDCG = 0.1574\n",
      "1238/1238 [==============================] - 19s 16ms/step - loss: 0.2832\n",
      "Iteration 68 Fit [20.6 s], Evaluate [0.1 s]: HR = 0.3062, MRR = 0.1259, NDCG = 0.1687\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2830\n",
      "Iteration 69 Fit [20.8 s], Evaluate [0.1 s]: HR = 0.3097, MRR = 0.1253, NDCG = 0.1689\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2828\n",
      "Iteration 70 Fit [21.9 s], Evaluate [0.4 s]: HR = 0.3055, MRR = 0.1279, NDCG = 0.1700\n",
      "1238/1238 [==============================] - 20s 16ms/step - loss: 0.2825\n",
      "Iteration 71 Fit [21.4 s], Evaluate [0.1 s]: HR = 0.2977, MRR = 0.1238, NDCG = 0.1651\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2823\n",
      "Iteration 72 Fit [21.8 s], Evaluate [0.1 s]: HR = 0.3104, MRR = 0.1317, NDCG = 0.1739\n",
      "1238/1238 [==============================] - 21s 17ms/step - loss: 0.2822\n",
      "Iteration 73 Fit [21.9 s], Evaluate [0.1 s]: HR = 0.2984, MRR = 0.1302, NDCG = 0.1701\n",
      "1238/1238 [==============================] - 19s 15ms/step - loss: 0.2819\n",
      "Iteration 74 Fit [20.3 s], Evaluate [0.1 s]: HR = 0.2899, MRR = 0.1222, NDCG = 0.1620\n",
      " 170/1238 [===>..........................] - ETA: 16s - loss: 0.2794"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_800/3271436553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "for epoch in range(1, epoch_num + 101):\n",
    "    t1 = time()\n",
    "    model.fit(\n",
    "            x=train_data,\n",
    "            epochs=1,\n",
    "            batch_size=batch_size)\n",
    "    t2 = time()\n",
    "    eval_dict = eval_pos_neg(model, test_data, ['hr', 'mrr', 'ndcg'], 10, batch_size)\n",
    "    print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, MRR = %.4f, NDCG = %.4f'\n",
    "              % (epoch, t2 - t1, time() - t2, eval_dict['hr'], eval_dict['mrr'], eval_dict['ndcg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9725cf-0012-418f-bd02-be06cc7ab1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant([[2558, 2559, 2582, 2605, 2608, 2669, 2801, 2835, 2913, 3052]])\n",
    "tf.print(tf.argmax(model(a)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79481e70-93d3-41d1-8e5b-558125f5da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def train_model(model,ds_train,ds_valid,epoches):\n",
    "\n",
    "    for epoch in tf.range(1,epoches+1):\n",
    "        model.reset_metrics()\n",
    "        \n",
    "        # 在后期降低学习率\n",
    "        if epoch == 5000:\n",
    "            model.optimizer.lr.assign(model.optimizer.lr/2.0)\n",
    "            tf.print(\"Lowering optimizer Learning Rate...\\n\\n\")\n",
    "        \n",
    "        for x, y in ds_train:\n",
    "            train_result = model.train_on_batch(x, y)\n",
    "\n",
    "        for x, y in ds_valid:\n",
    "            valid_result = model.test_on_batch(x, y,reset_metrics=False)\n",
    "            \n",
    "        if epoch%100 ==0:\n",
    "            tf.print(\"epoch = \",epoch)\n",
    "            print(\"train:\",dict(zip(model.metrics_names,train_result)))\n",
    "            print(\"valid:\",dict(zip(model.metrics_names,valid_result)))\n",
    "            print(\"\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a286ada-d7d0-4faf-a82c-43c935a51ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train_model(model,ds_train,ds_test,800)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5556bce-de04-45f2-8984-188580027175",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "items_num=3416\n",
    "maxlen=100\n",
    "len_seq=50\n",
    "batch_size=512\n",
    "epoch_num=70\n",
    "hidden_size=64\n",
    "keep_rate=0.9\n",
    "layers_num=2\n",
    "num_interest=1\n",
    "neg_num=4\n",
    "test_neg_num=100\n",
    "\n",
    "567/567 [==============================] - 8s 14ms/step - loss: 0.0797\n",
    "Iteration 1 Fit [8.2 s], Evaluate [0.3 s]: HR = 0.2048, MRR = 0.0723, NDCG = 0.1035\n",
    "567/567 [==============================] - 9s 16ms/step - loss: 0.0793\n",
    "Iteration 2 Fit [9.1 s], Evaluate [0.3 s]: HR = 0.2171, MRR = 0.0774, NDCG = 0.1102\n",
    "567/567 [==============================] - 9s 15ms/step - loss: 0.0786\n",
    "Iteration 3 Fit [9.0 s], Evaluate [0.2 s]: HR = 0.2142, MRR = 0.0769, NDCG = 0.1091\n",
    "567/567 [==============================] - 9s 15ms/step - loss: 0.0780\n",
    "Iteration 4 Fit [9.0 s], Evaluate [0.3 s]: HR = 0.2151, MRR = 0.0766, NDCG = 0.1091\n",
    "567/567 [==============================] - 9s 15ms/step - loss: 0.0778\n",
    "Iteration 5 Fit [8.9 s], Evaluate [0.2 s]: HR = 0.2141, MRR = 0.0776, NDCG = 0.1097\n",
    "567/567 [==============================] - 9s 16ms/step - loss: 0.0770\n",
    "Iteration 6 Fit [9.0 s], Evaluate [0.2 s]: HR = 0.2190, MRR = 0.0788, NDCG = 0.1117\n",
    "567/567 [==============================] - 9s 15ms/step - loss: 0.0764\n",
    "Iteration 7 Fit [9.0 s], Evaluate [0.2 s]: HR = 0.2151, MRR = 0.0773, NDCG = 0.1097\n",
    "567/567 [==============================] - 9s 15ms/step - loss: 0.0761\n",
    "Iteration 8 Fit [8.9 s], Evaluate [0.2 s]: HR = 0.2146, MRR = 0.0770, NDCG = 0.1094\n",
    "567/567 [==============================] - 6s 11ms/step - loss: 0.0756\n",
    "Iteration 9 Fit [6.4 s], Evaluate [0.2 s]: HR = 0.2147, MRR = 0.0775, NDCG = 0.1097\n",
    "567/567 [==============================] - 8s 14ms/step - loss: 0.0751\n",
    "Iteration 10 Fit [8.3 s], Evaluate [0.2 s]: HR = 0.2166, MRR = 0.0778, NDCG = 0.1104\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e66217-f349-4dc4-85fe-a8d250b20e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d3066-cf31-42a9-93cd-09f61bdfbb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
