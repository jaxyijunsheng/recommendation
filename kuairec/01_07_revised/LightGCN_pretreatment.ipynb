{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import random\n",
    "import pickle\n",
    "max_lenth=1000\n",
    "neg_num=4\n",
    "test_neg_num=100\n",
    "\n",
    "with open(\"D:/datasets/kuairec/small_matrix.pkl\",'rb') as f:\n",
    "    all_data=pickle.load(f)\n",
    "items_num=max(max(all_data.values()))\n",
    "train_set=[]\n",
    "val_set=[]\n",
    "test_set=[]\n",
    "for u in all_data.keys():\n",
    "    slice_data=all_data[u][0:max_lenth]\n",
    "    \n",
    "    test_data=choice(slice_data)\n",
    "    slice_data.remove(test_data)\n",
    "    \n",
    "    val_data=choice(slice_data)\n",
    "    slice_data.remove(val_data)\n",
    "    \n",
    "    train_data=slice_data\n",
    "    for i in train_data:\n",
    "        train_set.append([u,i])\n",
    "    val_set.append([u,val_data])\n",
    "    test_set.append([u,test_data])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411 1762\n"
     ]
    }
   ],
   "source": [
    "users=[]\n",
    "items=[]\n",
    "for l in train_set:\n",
    "    uid=int(l[0])\n",
    "    item=int(l[1])\n",
    "    users.append(uid)\n",
    "    items.append(item)\n",
    "for l in val_set:\n",
    "    uid=int(l[0])\n",
    "    item=int(l[1])\n",
    "    users.append(uid)\n",
    "    items.append(item)\n",
    "for l in test_set:\n",
    "    uid=int(l[0])\n",
    "    item=int(l[1])\n",
    "    users.append(uid)\n",
    "    items.append(item)\n",
    "users=list(set(users))\n",
    "items=list(set(items))\n",
    "print(len(users),len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "R = sp.dok_matrix((len(users),items_num), dtype=np.float32)\n",
    "for i in train_set:\n",
    "    R[i[0]-1, i[1]-1] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already create adjacency matrix (4738, 4738)\n",
      "already create adjacency matrix (4738, 4738)\n",
      "already create adjacency matrix (4738, 4738)\n",
      "already create adjacency matrix (4738, 4738)\n",
      "already create adjacency matrix (4738, 4738)\n",
      "generate single-normalized adjacency matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junyachen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in power\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate single-normalized adjacency matrix.\n"
     ]
    }
   ],
   "source": [
    "adj_mat = sp.dok_matrix((len(users)+items_num,len(users)+items_num), dtype=np.float32)\n",
    "adj_mat = adj_mat.tolil()\n",
    "R = R.tolil()\n",
    "for i in range(5):\n",
    "    adj_mat[int(len(users)*i/5.0):int(len(users)*(i+1.0)/5), len(users):] =\\\n",
    "    R[int(len(users)*i/5.0):int(len(users)*(i+1.0)/5)]\n",
    "    adj_mat[len(users):,int(len(users)*i/5.0):int(len(users)*(i+1.0)/5)] =\\\n",
    "    R[int(len(users)*i/5.0):int(len(users)*(i+1.0)/5)].T\n",
    "    adj_mat = adj_mat.todok()\n",
    "    print('already create adjacency matrix', adj_mat.shape)\n",
    "    def normalized_adj_single(adj):\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "        d_inv = np.power(rowsum, -1).flatten()\n",
    "        d_inv[np.isinf(d_inv)] = 0.\n",
    "        d_mat_inv = sp.diags(d_inv)\n",
    "        norm_adj = d_mat_inv.dot(adj)\n",
    "        print('generate single-normalized adjacency matrix.')\n",
    "        return norm_adj.tocoo()\n",
    "    def check_adj_if_equal(adj):\n",
    "        dense_A = np.array(adj.todense())\n",
    "        degree = np.sum(dense_A, axis=1, keepdims=False)\n",
    "        temp = np.dot(np.diag(np.power(degree, -1)), dense_A)\n",
    "        print('check normalized adjacency matrix whether equal to this laplacian matrix.')\n",
    "        return temp\n",
    "        \n",
    "norm_adj_mat = normalized_adj_single(adj_mat + sp.eye(adj_mat.shape[0]))\n",
    "mean_adj_mat = normalized_adj_single(adj_mat)\n",
    "adj_mat, norm_adj_mat, mean_adj_mat=adj_mat.tocsr(), norm_adj_mat.tocsr(), mean_adj_mat.tocsr()\n",
    "sp.save_npz('D:/datasets/kuairec/' + '/kuairec_small_s_adj_mat.npz', adj_mat)\n",
    "sp.save_npz('D:/datasets/kuairec/' + '/kuairec_small_s_norm_adj_mat.npz', norm_adj_mat)\n",
    "sp.save_npz('D:/datasets/kuairec/' + '/kuairec_small_s_mean_adj_mat.npz', mean_adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already load adj matrix (4738, 4738)\n"
     ]
    }
   ],
   "source": [
    "adj_mat = sp.load_npz('D:/datasets/kuairec/' + '/kuairec_small_s_adj_mat.npz')\n",
    "norm_adj_mat = sp.load_npz('D:/datasets/kuairec/' + '/kuairec_small_s_norm_adj_mat.npz')\n",
    "mean_adj_mat = sp.load_npz('D:/datasets/kuairec/' + '/kuairec_small_s_mean_adj_mat.npz')\n",
    "print('already load adj matrix', adj_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junyachen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in power\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate pre adjacency matrix.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pre_adj_mat = sp.load_npz('D:/datasets/kuairec/' + '/kuairec_small_s_pre_adj_mat.npz')\n",
    "except Exception:\n",
    "    adj_mat=adj_mat\n",
    "    rowsum = np.array(adj_mat.sum(1))\n",
    "    d_inv = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    norm_adj = d_mat_inv.dot(adj_mat)\n",
    "    norm_adj = norm_adj.dot(d_mat_inv)\n",
    "    print('generate pre adjacency matrix.')\n",
    "    pre_adj_mat = norm_adj.tocsr()\n",
    "    sp.save_npz('D:/datasets/kuairec/' + '/kuairec_small_s_pre_adj_mat.npz', norm_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict={}\n",
    "val_dict={}\n",
    "test_dict={}\n",
    "\n",
    "new_train_set=[]\n",
    "new_val_set=[]\n",
    "new_test_set=[]\n",
    "\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(val_set)\n",
    "random.shuffle(test_set)\n",
    "\n",
    "for i in train_set:\n",
    "    neg_item = [random.randint(1, items_num) for _ in range(neg_num)]\n",
    "    new_train_set.append((i[0],i[1],neg_item))\n",
    "\n",
    "for i in val_set:\n",
    "    neg_item = [random.randint(1, items_num) for _ in range(neg_num)]\n",
    "    new_val_set.append((i[0],i[1],neg_item))\n",
    "\n",
    "for i in test_set:\n",
    "    neg_item = [random.randint(1, items_num) for _ in range(test_neg_num)]\n",
    "    new_test_set.append((i[0],i[1],neg_item))\n",
    "    \n",
    "users, pos_items,neg_items = zip(*new_train_set)\n",
    "train_dict = {'users': np.array(users), 'pos_item': np.array(pos_items),'neg_item':np.array(neg_items)}\n",
    "\n",
    "users, pos_items,neg_items = zip(*new_val_set)\n",
    "val_dict = {'users': np.array(users), 'pos_item': np.array(pos_items),'neg_item':np.array(neg_items)}\n",
    "\n",
    "users, pos_items,neg_items = zip(*new_test_set)\n",
    "test_dict = {'users': np.array(users), 'pos_item': np.array(pos_items),'neg_item':np.array(neg_items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/datasets/kuairec/small_matrix_gcn_train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dict, f, -1)\n",
    "with open('D:/datasets/kuairec/small_matrix_gcn_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(val_dict, f, -1)\n",
    "with open('D:/datasets/kuairec/small_matrix_gcn_val_data.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dict, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408178 1411 1411 3327\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set),len(test_set),len(val_set),items_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
